---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /home/
---

About Me
======
<strong>Short Bio:</strong> I am currently a third-year Ph.D. student in the [Research School of Computing](https://comp.anu.edu.au/), [Australian National University](https://www.anu.edu.au/), supervised by [Prof. Stephen Gould](https://users.cecs.anu.edu.au/~sgould/) and [Prof. Liang Zheng](https://zheng-lab-anu.github.io/). Before that, I received my master's degree in computing from [Australian National University](https://www.anu.edu.au/) in 2022 and my bachelor's degree in mathematics from [Peking University](https://www.pku.edu.cn) in 2019.

<strong>Research interest: </strong>I have broad interest in computer vision especially autoregressive modeling, including both autoregressive visual understanding and generation.

------

Publications
======

## Visual Generation
<div style="display: flex; align-items: center; margin-bottom: 1.2em;">
  <img src="/images/pub/simflow.png"
       alt="SimFlow thumbnail"
       style="width: 120px; height: auto; margin-right: 16px;">
  <div>
    <strong>SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows</strong><br>
    <strong>Qinyu Zhao</strong>, Guangting Zheng, Tao Yang, Rui Zhu, Xingjian Leng, Stephen Gould, Liang Zheng<br>
    <em>ArXiv preprint, 2025</em><br>
    ğŸ“„ <a href="https://arxiv.org/abs/2512.04084">Preprint</a> |
    ğŸŒ <a href="https://qinyu-allen-zhao.github.io/SimFlow/">Project page</a> |  | 
    ğŸ’» <a href="https://github.com/ByteDance-Seed/SimFlow">Code</a>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 1.2em;">
  <img src="/images/pub/disa.png"
       alt="DiSA thumbnail"
       style="width: 120px; height: auto; margin-right: 16px;">
  <div>
    <strong>DiSA: Diffusion Step Annealing in Autoregressive Image Generation</strong><br>
    <strong>Qinyu Zhao</strong>, Jaskirat Singh, Ming Xu, Akshay Asthana, Stephen Gould, Liang Zheng<br>
    <em>ArXiv preprint, 2025</em><br>
    ğŸ“„ <a href="https://arxiv.org/abs/2505.20297">Preprint</a> |
    ğŸŒ <a href="https://qinyu-allen-zhao.github.io/DiSA/">Project page</a> | 
    ğŸ’» <a href="https://github.com/Qinyu-Allen-Zhao/DiSA">Code</a>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 1.2em;">
  <img src="/images/pub/arinar.png"
       alt="ARINAR thumbnail"
       style="width: 120px; height: auto; margin-right: 16px;">
  <div>
    <strong>ARINAR: Bi-Level Autoregressive Feature-by-Feature Generative Models</strong><br>
    <strong>Qinyu Zhao</strong>, Stephen Gould, Liang Zheng<br>
    <em>ArXiv preprint, 2025</em><br>
    ğŸ“„ <a href="https://arxiv.org/abs/2503.02883">Preprint</a> | 
    ğŸ’» <a href="https://github.com/Qinyu-Allen-Zhao/Arinar">Code</a>
  </div>
</div>

## Visual Understanding

<div style="display: flex; align-items: center; margin-bottom: 1.2em;">
  <img src="/images/pub/pred_lvlm.png"
       alt="Pred LVLM thumbnail"
       style="width: 120px; height: auto; margin-right: 16px;">
  <div>
    <strong>Can We Predict Performance of Large Models across Vision-Language Tasks?</strong><br>
    <strong>Qinyu Zhao</strong>, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, Stephen Gould<br>
    <em>International Conference on Machine Learning (ICML), 2025</em><br>
    ğŸ“„ <a href="https://arxiv.org/abs/2410.10112">Preprint</a> | 
    ğŸ’» <a href="https://github.com/Qinyu-Allen-Zhao/CrossPred-LVLM">Code</a>
  </div>
</div>

<div style="display: flex; align-items: center; margin-bottom: 1.2em;">
  <img src="/images/pub/lvlm_lp.png"
       alt="LVLM LP thumbnail"
       style="width: 120px; height: auto; margin-right: 16px;">
  <div>
    <strong>The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?</strong><br>
    <strong>Qinyu Zhao</strong>, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, Stephen Gould<br>
    <em>European Conference on Computer Vision (ECCV), 2024</em><br>
    ğŸ“„ <a href="https://arxiv.org/abs/2403.09037">Preprint</a> | 
    ğŸ’» <a href="https://github.com/Qinyu-Allen-Zhao/LVLM-LP">Code</a>
  </div>
</div>

## Out-of-Distribution Detection

<div style="display: flex; align-items: center; margin-bottom: 1.2em;">
  <img src="/images/pub/optfsood.png"
       alt="Opt FS OOD thumbnail"
       style="width: 120px; height: auto; margin-right: 16px;">
  <div>
    <strong>Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection</strong><br>
    <strong>Qinyu Zhao</strong>, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, Stephen Gould<br>
    <em>International Conference on Learning Representations (ICLR), 2024</em><br>
    ğŸ“„ <a href="https://arxiv.org/abs/2402.00865">Preprint</a> | 
    ğŸ’» <a href="https://github.com/Qinyu-Allen-Zhao/OptFSOOD">Code</a>
  </div>
</div>

------

Experience
======

* **ByteDance Seed, China**
    * **Role:** Research Intern in Generative Models
    * **Time:** Jun 2025 - Dec 2025

* **Australian National University, Australia**
    * **Role:** Teaching Assistant
    * **Time:** Jul 2022 - Present

* **Australian National University, Australia**
    * **Role:** Guest Lecturer - Introduce Weights & Biases
    * **Time:** Sep 2024
    * **Description:** Advanced Topics in Deep Learning for Computer Vision, 1 lecture

------

Awards
======

* **Chinese Government Award for Outstanding Self-Financed Students Abroad**
    * **Description:** Granted **USD6,000**. The highest government award to Chinese doctoral students who study overseas.
    * **Time:** 2025

* **Google Cloud Research Credits Program**
    * **Description:** Granted **USD7,808** in Google Cloud Platform credits to support large-scale training of vision-language models.
    * **Time:** Jul 2024 - Jul 2025

* **OpenAI Researcher Access Program**
    * **Description:** Awarded **USD5,000** in OpenAI API credits to support research on large multimodal models.
    * **Time:** Jun 2024 - Dec 2024
